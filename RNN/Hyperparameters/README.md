# Hyperparameters

## Concepts

* Introducing Jay
> For this section, we're introducing a new Udacity instructor, Jay Alammar. Jay has done some great work in interactive explorations of neural networks, check out his [blog](http://jalammar.github.io/).

>Jay will be reviewing some of the material you saw in the Deep Neural Networks section on hyperparameters, and he will also introduce the hyperparameters used in Recurrent Neural Networks.

* [Introduction](https://www.youtube.com/watch?v=erwnzFD7AeE)
	* Optimizer hyperparameter
		*lr, batch_size, epochs
	* Model hyperparameters
		*number of layers, model specific hyperparameters like RNN

* [Learning Rate](https://www.youtube.com/watch?time_continue=11&v=HLMjeDez7ps)
	* Adaptive Learning Optimizers
		* AdamOptimizer
		* AdagradOptimizer
	* Learning Rate Decay
		* Linear
		* Exponential Decay

* Quiz
	* [Quiz 1](images/quiz1_lr.png)
	* [Quiz 2](images/quiz2_lr.png)

* [Minibatch Size](https://www.youtube.com/watch?v=GrrO1NFxaW8)
	* Online (Stochastic)
	* Batch
	* Minibatch
	> [Systematic evaluation of CNN advances on the ImageNet](https://arxiv.org/abs/1606.02228) by Dmytro Mishkin, Nikolay Sergievskiy, Jiri Matas

* [Number Of Iterations](https://www.youtube.com/watch?time_continue=14&v=TTdHpSb4DV8)
	* Early stopping
* [Number Of Hidden Units Layers](https://www.youtube.com/watch?v=IkGAIQH5wH8)
	* [Andrej Karpathy](https://cs231n.github.io/neural-networks-1/)
	* [Capacity](http://www.deeplearningbook.org/contents/ml.html)

* [RNN Hyperparameters](https://www.youtube.com/watch?v=yQvnv7l_aUo)

* Quiz: RNN Hyperparameters
	* [Quiz1](images/quiz1_rnn.png)
	* [Quiz2](images/quiz2_rnn.png)

* Sources & References
	* Practical recommendations for gradient-based training of deep architectures by Yoshua Bengio

	* [Deep Learning book - chapter 11.4: Selecting Hyperparameters by Ian Goodfellow, Yoshua Bengio, Aaron Courville](http://www.deeplearningbook.org/contents/guidelines.html)

	* [Neural Networks and Deep Learning book - Chapter 3: How to choose a neural network's hyper-parameters? by Michael Nielsen](http://neuralnetworksanddeeplearning.com/chap3.html#how_to_choose_a_neural_network's_hyper-parameters)

	* Efficient BackProp (pdf) by Yann LeCun

	* How to Generate a Good Word Embedding? by Siwei Lai, Kang Liu, Liheng Xu, Jun Zhao
	* Systematic evaluation of CNN advances on the ImageNet by Dmytro Mishkin, Nikolay Sergievskiy, Jiri Matas
	* Visualizing and Understanding Recurrent Networks by Andrej Karpathy, Justin Johnson, Li Fei-Fei









