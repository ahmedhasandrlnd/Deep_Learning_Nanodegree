# Hyperparameters

## Concepts

* Introducing Jay
> For this section, we're introducing a new Udacity instructor, Jay Alammar. Jay has done some great work in interactive explorations of neural networks, check out his [blog](http://jalammar.github.io/).

>Jay will be reviewing some of the material you saw in the Deep Neural Networks section on hyperparameters, and he will also introduce the hyperparameters used in Recurrent Neural Networks.

* [Introduction](https://www.youtube.com/watch?v=erwnzFD7AeE)
	* Optimizer hyperparameter
		*lr, batch_size, epochs
	* Model hyperparameters
		*number of layers, model specific hyperparameters like RNN

* [Learning Rate](https://www.youtube.com/watch?time_continue=11&v=HLMjeDez7ps)
	* Adaptive Learning Optimizers
		* AdamOptimizer
		* AdagradOptimizer
	* Learning Rate Decay
		* Linear
		* Exponential Decay

* Quiz
	* [Quiz 1](images/quiz1_lr.png)
	* [Quiz 2](images/quiz2_lr.png)









